{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a5921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1efa9530",
   "metadata": {},
   "source": [
    "User Input\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "[Step 2] ‚Üí classify intent + extract entities via LLM\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "[Step 3] ‚Üí build SQL prompt using schema + examples\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "[Step 4] ‚Üí generate SQL via LLM\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "[Step 5] ‚Üí validate SQL\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "[Step 6] ‚Üí optional agentic reflection + fix SQL via LLM\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "[Step 7] ‚Üí execute SQL on SQLite\n",
    "   ‚îÇ\n",
    "   ‚ñº\n",
    "[Step 8] ‚Üí return final answer via LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599fa378",
   "metadata": {},
   "source": [
    "STEP 1: Intent & Entity Classification\n",
    "\n",
    "This step interprets the user‚Äôs natural language question to determine what kind of data they‚Äôre asking for and which details are relevant. This will be used to \n",
    "\n",
    "üîç Purpose:\n",
    "\n",
    "Turn a raw question like:\n",
    "\"How many rushing yards did Jalen Hurts have against Dallas in 2024?\"\n",
    "into structured metadata like:\n",
    "{\n",
    "  \"intent\": \"player_week\",\n",
    "  \"entities\": {\n",
    "    \"season\": 2024,\n",
    "    \"week\": null,\n",
    "    \"player\": \"Jalen Hurts\",\n",
    "    \"opponent\": \"DAL\"\n",
    "  }\n",
    "}\n",
    "\n",
    "This metadata will be used to create the SQL statement.\n",
    "\n",
    "WORKFLOW:\n",
    "1.\tDefine Supported Intents and Entities \n",
    "    a.\tThe system supports four kinds of questions:\n",
    "        i.\tplayer_season: full-season stats for a player\n",
    "        ii.\tplayer_week: opponent-specific or single-week stats for a player\n",
    "        iii. team_game: performance in a specific game/week\n",
    "        iv.\tteam_season: team-wide totals for an entire season\n",
    "    b. From the user question identify entities that can be passed to the LLM to help generate the SQL statement: season, week, player, opponent.\n",
    "2.\tBuild the Prompt for OpenAI\n",
    "    a.\tCreates a detailed system prompt that:\n",
    "        i.\tDescribes the 4 intent types\n",
    "        ii.\tAsks for extraction of fields: season, week, player, opponent\n",
    "        iii.\tProvides rules, like never treating \"PHI\" as the opponent\n",
    "        iv.\tRequires valid JSON output only ‚Äî no explanations\n",
    "3.\tCall the OpenAI Model\n",
    "    a.\tSends the prompt to the model (e.g., GPT-4o-mini) with strict formatting\n",
    "    b.\tExpects a structured JSON response\n",
    "4.\tParse and Clean the Model Output\n",
    "    a.\tRemoves any extra formatting (like ```json code blocks)\n",
    "    b.\tConverts the output string into a Python dictionary\n",
    "    c.\tValidates opponent (must be one of 32 NFL teams)\n",
    "    d.\tFills in missing fields with null if needed\n",
    "5.\tHandle Errors Gracefully\n",
    "    a.\tIf parsing fails or response is malformed:\n",
    "    b.\tDefault to intent = \"team_season\"\n",
    "    c.\tReturn empty entities (None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9210dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# -------------------------------\n",
    "# Load environment\n",
    "# -------------------------------\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# -------------------------------\n",
    "# Initialize OpenAI Client\n",
    "# -------------------------------\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    http_client=httpx.Client(verify=os.environ.get(\"REQUESTS_CA_BUNDLE\"))\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# NFL Teams\n",
    "# -------------------------------\n",
    "NFL_TEAMS = [\n",
    "    \"ARI\",\"ATL\",\"BAL\",\"BUF\",\"CAR\",\"CHI\",\"CIN\",\"CLE\",\"DAL\",\"DEN\",\n",
    "    \"DET\",\"GB\",\"HOU\",\"IND\",\"JAX\",\"KC\",\"LV\",\"LAC\",\"LAR\",\"MIA\",\n",
    "    \"MIN\",\"NE\",\"NO\",\"NYG\",\"NYJ\",\"PHI\",\"PIT\",\"SEA\",\"SF\",\"TB\",\n",
    "    \"TEN\",\"WAS\"\n",
    "]\n",
    "\n",
    "team_list = \", \".join(NFL_TEAMS)\n",
    "# -------------------------------\n",
    "# Helper: Normalize CJ ‚Üí C.J.\n",
    "# -------------------------------\n",
    "def normalize_player_name(name: str) -> str:\n",
    "    if name is None:\n",
    "        return None\n",
    "\n",
    "    parts = name.split()\n",
    "    if len(parts) > 1 and len(parts[0]) in {2, 3} and parts[0].isupper():\n",
    "        # Convert AJ ‚Üí A.J.   CJ ‚Üí C.J.\n",
    "        initials = \".\".join(parts[0]) + \".\"\n",
    "        return f\"{initials} {' '.join(parts[1:])}\"\n",
    "\n",
    "    return name\n",
    "\n",
    "# -------------------------------\n",
    "# Intent + Entity Classifier\n",
    "# -------------------------------\n",
    "def classify_intent_and_extract_entities(question: str) -> dict:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a classifier and entity extractor for a sports assistant focused on the Philadelphia Eagles.\n",
    "\n",
    "You MUST return JSON in exactly the following structure:\n",
    "{{\n",
    "  \"intent\": \"player_season | player_week | team_game | team_season\",\n",
    "  \"entities\": {{\n",
    "    \"season\": integer or null,\n",
    "    \"week\": integer or null,\n",
    "    \"player\": string or null,\n",
    "    \"opponent\": string or null\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Do NOT return JSON that is missing the \"intent\" or \"entities\" fields.\n",
    "\n",
    "---\n",
    "\n",
    "Your job is to:\n",
    "1. Classify the question into one of these intents:\n",
    "   - \"player_season\": full-season stats for a specific player (e.g. total TDs in 2023)\n",
    "   - \"player_week\": weekly or opponent-specific stats for a player (e.g. vs Dallas or Week 9)\n",
    "   - \"team_game\": team performance in a specific game or week\n",
    "   - \"team_season\": team-wide totals for an entire season\n",
    "\n",
    "2. Extract the following fields inside the \"entities\" object:\n",
    "   - \"season\": integer (e.g. 2023) or null\n",
    "   - \"week\": integer (e.g. 9) or null\n",
    "   - \"player\": string (e.g. \"Jalen Hurts\" or \"A.J. Brown\") or null\n",
    "   - \"opponent\": NFL team code (e.g. \"DAL\") or null\n",
    "\n",
    "Guidelines:\n",
    "- PHI should never be extracted as the opponent ‚Äî the team is always the Eagles.\n",
    "- Only extract opponents that are in this list: {team_list}\n",
    "- Preserve initials in names like \"A.J. Brown\", \"C.J. Gardner-Johnson\"\n",
    "- Return valid JSON only ‚Äî no explanations, no formatting, no markdown fences.\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=200\n",
    "        )\n",
    "\n",
    "        raw = response.choices[0].message.content\n",
    "        #print(\"RAW MODEL OUTPUT:\", repr(raw))\n",
    "\n",
    "        # Strip code fences if present\n",
    "        if raw.startswith(\"```\"):\n",
    "            raw = re.sub(r\"```(json)?\", \"\", raw).strip(\"` \\n\")\n",
    "\n",
    "        # Parse JSON\n",
    "        result = json.loads(raw)\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # üî• FIX: Convert flat structure ‚Üí nested structure\n",
    "        # ----------------------------------------------------\n",
    "        if \"entities\" not in result:\n",
    "            result = {\n",
    "                \"intent\": result.get(\"intent\", \"team_season\"),\n",
    "                \"entities\": {\n",
    "                    \"season\": result.get(\"season\"),\n",
    "                    \"week\": result.get(\"week\"),\n",
    "                    \"player\": result.get(\"player\"),\n",
    "                    \"opponent\": result.get(\"opponent\")\n",
    "                }\n",
    "            }\n",
    "\n",
    "        entities = result[\"entities\"]\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # Normalize opponent field\n",
    "        # ----------------------------------------------------\n",
    "        opp = entities.get(\"opponent\")\n",
    "        if opp:\n",
    "            opp = opp.upper()\n",
    "            entities[\"opponent\"] = opp if opp in NFL_TEAMS else None\n",
    "        else:\n",
    "            entities[\"opponent\"] = None\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # Normalize player name (AJ ‚Üí A.J.)\n",
    "        # ----------------------------------------------------\n",
    "        entities[\"player\"] = normalize_player_name(entities.get(\"player\"))\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # Validate intent\n",
    "        # ----------------------------------------------------\n",
    "        valid_intents = {\"player_week\", \"player_season\", \"team_game\", \"team_season\"}\n",
    "        if result.get(\"intent\") not in valid_intents:\n",
    "            result[\"intent\"] = \"team_season\"\n",
    "\n",
    "        # Return final normalized result\n",
    "        return {\n",
    "            \"intent\": result[\"intent\"],\n",
    "            \"entities\": entities\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"JSON PARSE ERROR:\", e)\n",
    "        return {\n",
    "            \"intent\": \"team_season\",\n",
    "            \"entities\": {\n",
    "                \"season\": None,\n",
    "                \"week\": None,\n",
    "                \"player\": None,\n",
    "                \"opponent\": None\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b6fd60",
   "metadata": {},
   "source": [
    "STEP 2: SQL Builder\n",
    "\n",
    "This step transforms the classified intent and extracted entities into a structured SQL query that can be executed on our SQLite database.\n",
    "\n",
    "PURPOSE: Turn metadata like:\n",
    "{\n",
    "  \"intent\": \"player_week\",\n",
    "  \"entities\": {\n",
    "    \"season\": 2024,\n",
    "    \"week\": null,\n",
    "    \"player\": \"Jalen Hurts\",\n",
    "    \"opponent\": \"DAL\"\n",
    "  }\n",
    "}\n",
    " Into a valid SQL query like:\n",
    "\n",
    "SELECT SUM(rushing_yards) AS total_rushing_yards\n",
    "FROM player_week\n",
    "WHERE player_display_name = 'Jalen Hurts'\n",
    "  AND opponent_team = 'DAL'\n",
    "  AND season = 2024;\n",
    "\n",
    "This SQL is later executed against the SQLite database to retrieve the final answer.\n",
    "\n",
    "WORKFLOW\n",
    "1. Select the Table\n",
    "\n",
    "The system maps the classified intent to the correct table:\n",
    "\n",
    "| Intent Type     | Meaning                                     | Table Used    |\n",
    "| --------------- | ------------------------------------------- | ------------- |\n",
    "| `player_week`   | Player stats by week or against an opponent | `player_week` |\n",
    "| `player_season` | Full-season player totals                   | `players`     |\n",
    "| `team_game`     | Team performance in a specific game/week    | `games`       |\n",
    "| `team_season`   | Full-season team totals                     | `seasons`     |\n",
    "\n",
    "2. Retrieve the Table Schema\n",
    "The builder uses:PRAGMA table_info(<table_name>);\n",
    "This retrieves:\n",
    "\n",
    "column names\n",
    "column types\n",
    "primary keys\n",
    "\n",
    "The schema is passed to the LLM so the model knows exactly what fields exist and avoids hallucinating columns.\n",
    "\n",
    "3. Build the Prompt for the LLM\n",
    "\n",
    "The SQL Builder constructs a natural-language prompt containing:\n",
    "\n",
    "    1.The table name\n",
    "    2.The full schema\n",
    "    3.The user‚Äôs question\n",
    "    4.Rules for safe SQL generation:\n",
    "        a.Use only valid SQLite syntax\n",
    "        b.Filter on:\n",
    "            season\n",
    "            week\n",
    "            player_display_name\n",
    "            opponent_team\n",
    "        c.Avoid filtering by PHI (every row is already Eagles data)\n",
    "        d.Aggregate metrics (e.g., SUM) if multiple rows are implied.\n",
    "        \n",
    "This gives the model all context needed to generate correct SQL.\n",
    "\n",
    "4. Generate SQL Using OpenAI: The builder calls the LLM to produce SQL\n",
    "5. Clean and Format SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "\n",
    "#--------------------------------\n",
    "#SQL Rules\n",
    "#--------------------------------\n",
    "\n",
    "\n",
    "def sql_rules(team_list: str) -> str:\n",
    "    return (\n",
    "            \"- Use ONLY the extracted entities above when building the WHERE clause.\\n\"\n",
    "            \"- NEVER pull team names or player names from the natural language question.\\n\"\n",
    "            \"- Use player_display_name for player filters.\\n\"\n",
    "            \"- Do NOT filter by team since all teams are PHI\\n\" \n",
    "            \"- If the user asks for total 'yards' for a player, include both `passing_yards` and `rushing_yards` if available.\\n\"\n",
    "            \"- If the user asks about a change over be sure to include relevant time fields like year or week\\n\"\n",
    "            \"- If including filters for position, only use standard abbreviations (e.g., 'QB', 'WR', 'RB').\\n\"\n",
    "            \"- Do NOT include any field in the WHERE clause that is not listed in the table schema.\\n\"\n",
    "            f\"- Only extract opponents that are in this list: {team_list}\"\n",
    "            )\n",
    "\n",
    "sql_rules_text = sql_rules(team_list)\n",
    "\n",
    "# -------------------------------\n",
    "# Table Selector Based on Intent\n",
    "# -------------------------------\n",
    "def select_table(intent: str) -> str:\n",
    "    return {\n",
    "        \"player_week\": \"player_week\",\n",
    "        \"player_season\": \"players\",\n",
    "        \"team_game\": \"games\",\n",
    "        \"team_season\": \"seasons\"\n",
    "    }.get(intent, \"seasons\")\n",
    "\n",
    "# -------------------------------\n",
    "# Get Table Schema (PRAGMA)\n",
    "# -------------------------------\n",
    "def get_table_schema(db_path: str, table_name: str) -> str:\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        cursor = conn.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = cursor.fetchall()\n",
    "        schema_lines = [f\"{col[1]} ({col[2]})\" for col in columns]\n",
    "        return \"\\n\".join(schema_lines)\n",
    "\n",
    "# -------------------------------\n",
    "# SQL Prompt Builder\n",
    "# -------------------------------\n",
    "def build_sql_prompt(question: str, schema: str, table: str, intent: str, entities: dict) -> str:\n",
    "    season = entities.get(\"season\")\n",
    "    week = entities.get(\"week\")\n",
    "    player = entities.get(\"player\")\n",
    "    opponent = entities.get(\"opponent\")\n",
    "\n",
    "    # Build structured entity hint for LLM\n",
    "    entity_block = f\"\"\"\n",
    "EXTRACTED ENTITIES (use ONLY these values):\n",
    "- season: {season}\n",
    "- week: {week}\n",
    "- player: {player}\n",
    "- opponent: {opponent}\n",
    "\"\"\"\n",
    "\n",
    "    needs_aggregation = False\n",
    "    if intent in (\"player_week\", \"player_season\"):\n",
    "        if opponent and not week:\n",
    "            needs_aggregation = True\n",
    "        if week is None:\n",
    "            needs_aggregation = True\n",
    "\n",
    "    aggregation_rule = \"\"\n",
    "    if needs_aggregation and table == \"player_week\":\n",
    "        aggregation_rule = (\n",
    "            \"- If multiple rows match (e.g., multiple weeks vs same opponent), \"\n",
    "            \"use SUM() for numeric fields.\\n\"\n",
    "        )\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a data assistant that writes valid SQLite SQL queries.\n",
    "\n",
    "TABLE NAME: {table}\n",
    "SCHEMA:\n",
    "{schema}\n",
    "\n",
    "{entity_block}\n",
    "\n",
    "Rules:\n",
    "{sql_rules_text}\n",
    "\n",
    "{aggregation_rule}- Return ONLY the SQL query with no commentary.\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "    print(\"üü© SQL Prompt:\\n\", prompt)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# SQL Generation via LLM\n",
    "# -------------------------------\n",
    "def generate_sql_query(prompt: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    sql = response.choices[0].message.content\n",
    "\n",
    "    # Clean up markdown-style code block if present\n",
    "    if sql.startswith(\"```\"):\n",
    "        sql = re.sub(r\"```(sql)?\", \"\", sql).strip(\"` \\n\")\n",
    "\n",
    "    \"\"\"print(\"üü¶ FINAL SQL QUERY:\\n\", sql)\"\"\"\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1fed5",
   "metadata": {},
   "source": [
    "STEP 3: SQL Execution- take the generated SQL and run it against SQLlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7366b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def run_sql_query(db_path: str, query: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executes a generated SQL query against the SQLite database.\n",
    "    Returns the results as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå SQL EXECUTION ERROR:\", e)\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f1691",
   "metadata": {},
   "source": [
    "STEP 4: AGENTIC REFLECTION TO ASSESS SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "378ce94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_query_results(user_question: str, sql: str, query_results) -> str:\n",
    "    \"\"\"\n",
    "    Reflects on the SQL and results, and determines whether the output answers the user‚Äôs question.\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(query_results, \"to_string\"):\n",
    "        results_str = query_results.to_string(index=False)\n",
    "    else:\n",
    "        results_str = str(query_results)\n",
    "\n",
    "    reflect_prompt = f\"\"\"You are a data assistant that evaluates whether a SQL query correctly answered a user's question.\n",
    "\n",
    "Instructions:\n",
    "- Look at the original user question.\n",
    "- Examine the SQL query that was used to answer it.\n",
    "- Review the returned results.\n",
    "- Then determine:\n",
    "  1. Did the SQL query match the user‚Äôs intent?\n",
    "  2. Were the correct filters, fields, and aggregations used?\n",
    "  3. Were all given rules followed?\n",
    "  4. Do the results look reasonable?\n",
    "- If correct, write a brief natural language answer.\n",
    "- If incorrect, explain what went wrong (e.g. wrong column, filter, aggregation, etc.)\n",
    "\n",
    "Rules:\n",
    "    -filtering for team='PHI' is not necessary since all data is for the Eagles.\n",
    "\n",
    "USER QUESTION:\n",
    "{user_question}\n",
    "\n",
    "GENERATED SQL:\n",
    "{sql}\n",
    "\n",
    "Rules:\n",
    "{sql_rules}\n",
    "\n",
    "QUERY RESULTS:\n",
    "{results_str}\n",
    "\"\"\"\n",
    "\n",
    "    #print(\"üß† Reflection Prompt:\\n\", reflect_prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": reflect_prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content.strip()\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba824d64",
   "metadata": {},
   "source": [
    "STEP 5: REGENERATE SQL IF NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8e64fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regenerated_sql(user_question: str, reflection: str, previous_sql: str, schema: str, table: str, intent: str, entities: dict) -> str:\n",
    "\n",
    "    regen_prompt = f\"\"\"\n",
    "You are a SQL assistant. Your job is to revise a previous SQL query that failed to correctly answer a user's question.\n",
    "\n",
    "üü® Original User Question:\n",
    "{user_question}\n",
    "\n",
    "üü• Identified Problem with Previous SQL:\n",
    "{reflection}\n",
    "\n",
    "üßæ Previous SQL:\n",
    "{previous_sql}\n",
    "\n",
    "üìò Table Information:\n",
    "- Table name: {table}\n",
    "- Intent: {intent}\n",
    "- Extracted entities: {json.dumps(entities, indent=2)}\n",
    "- Table schema:\n",
    "{schema}\n",
    "\n",
    "Rules:\n",
    "{sql_rules_text}\n",
    "üéØ Goal:\n",
    "Fix the SQL so it accurately answers the user‚Äôs question and follows all rules. Only return valid SQLite SQL ‚Äî no commentary or markdown formatting.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": regen_prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    new_sql = response.choices[0].message.content\n",
    "\n",
    "    # Clean up markdown-style code block if present\n",
    "    if new_sql.startswith(\"```\"):\n",
    "      new_sql = re.sub(r\"```(sql)?\", \"\", new_sql).strip(\"` \\n\")\n",
    "\n",
    "    \"\"\"print(\"üü™ REVISED SQL QUERY:\\n\", new_sql)\"\"\"\n",
    "    return new_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb5a47",
   "metadata": {},
   "source": [
    "6.RUN SQL FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19117eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_query(db_path: str, query: str):\n",
    "    import sqlite3\n",
    "    import pandas as pd\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        return pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167cbea",
   "metadata": {},
   "source": [
    "7. EVALUATE REFLECTION FEEDBACK AND DETERMINE IF REGENERATION IS NECESSARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "944692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_regenerate(reflection_summary: str, df_result: pd.DataFrame) -> bool:\n",
    "    # 1. If empty result, almost always regenerate\n",
    "    if df_result.empty:\n",
    "        return True\n",
    "\n",
    "    # 2. If reflection says it failed\n",
    "    failure_keywords = [\n",
    "        \"did not successfully answer\",\n",
    "        \"did not address\",\n",
    "        \"does not address\",\n",
    "        \"did not correctly\",\n",
    "        \"does not correctly\",\n",
    "        \"incorrectly\",\n",
    "        \"failed to\",\n",
    "        \"no data\",\n",
    "        \"returned None\",\n",
    "        \"no records found\",\n",
    "        \"issue with the query\",\n",
    "        \"mismatch\",\n",
    "        \"missing\"\n",
    "    ]\n",
    "    if any(kw in reflection_summary.lower() for kw in failure_keywords):\n",
    "        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adf4a8",
   "metadata": {},
   "source": [
    "WRAPPED FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a1559692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query_pipeline(question: str):\n",
    "    from paths import SQLITE_DB_PATH\n",
    "\n",
    "    # 1Ô∏è‚É£ Intent + Entity Extraction\n",
    "    parsed = classify_intent_and_extract_entities(question)\n",
    "    intent = parsed[\"intent\"]\n",
    "    entities = parsed[\"entities\"]\n",
    "\n",
    "    # 2Ô∏è‚É£ Table Selection\n",
    "    table = select_table(intent)\n",
    "\n",
    "    # 3Ô∏è‚É£ Schema Lookup\n",
    "    schema = get_table_schema(SQLITE_DB_PATH, table)\n",
    "\n",
    "    # 4Ô∏è‚É£ SQL Prompt Build\n",
    "    prompt = build_sql_prompt(question, schema, table, intent, entities)\n",
    "\n",
    "    # 5Ô∏è‚É£ SQL Generation\n",
    "    sql = generate_sql_query(prompt)\n",
    "\n",
    "    # 6Ô∏è‚É£ SQL Execution\n",
    "    df_result = run_sql_query(SQLITE_DB_PATH, sql)\n",
    "\n",
    "    # 7Ô∏è‚É£ Reflection\n",
    "    reflection_summary = reflect_query_results(question, sql, df_result)\n",
    "\n",
    "    # 8Ô∏è‚É£ Conditional Regeneration\n",
    "    regenerated_sql = None\n",
    "    if should_regenerate(reflection_summary, df_result):\n",
    "        regenerated_sql = build_regenerated_sql(\n",
    "            question, reflection_summary, sql, schema, table, intent, entities\n",
    "        )\n",
    "        df_result = run_sql_query(SQLITE_DB_PATH, regenerated_sql)\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"intent\": intent,\n",
    "        \"entities\": entities,\n",
    "        \"table\": table,\n",
    "        \"original_sql\": sql,\n",
    "        \"regenerated_sql\": regenerated_sql,\n",
    "        \"result\": df_result,\n",
    "        \"reflection\": reflection_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bb4ab3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü© SQL Prompt:\n",
      " \n",
      "You are a data assistant that writes valid SQLite SQL queries.\n",
      "\n",
      "TABLE NAME: games\n",
      "SCHEMA:\n",
      "season (INTEGER)\n",
      "game_id (TEXT)\n",
      "week (INTEGER)\n",
      "is_home (INTEGER)\n",
      "opponent (TEXT)\n",
      "league_team_count (INTEGER)\n",
      "points_scored (INTEGER)\n",
      "points_allowed (INTEGER)\n",
      "margin_of_victory (INTEGER)\n",
      "win (INTEGER)\n",
      "cum_points_for_sum (INTEGER)\n",
      "cum_points_against_sum (INTEGER)\n",
      "cum_margin_sum (INTEGER)\n",
      "cumulative_wins (INTEGER)\n",
      "cumulative_win_pct (REAL)\n",
      "cum_win_pct (REAL)\n",
      "cum_win_pct_rank_vs_league (REAL)\n",
      "cum_win_pct_z_vs_league (REAL)\n",
      "turnovers_committed (INTEGER)\n",
      "turnovers_forced (INTEGER)\n",
      "turnover_differential (INTEGER)\n",
      "cum_tov_diff (INTEGER)\n",
      "cum_tov_diff_per_g (REAL)\n",
      "cum_tov_diff_per_g_rank_vs_league (REAL)\n",
      "cum_tov_diff_per_g_z_vs_league (REAL)\n",
      "total_yards_gained (REAL)\n",
      "total_yards_allowed (REAL)\n",
      "cum_yards_gained_sum (REAL)\n",
      "cum_yards_allowed_sum (REAL)\n",
      "cum_yards_gained_per_g (REAL)\n",
      "cum_yards_allowed_per_g (REAL)\n",
      "cum_yards_gained_per_g_rank_vs_league (REAL)\n",
      "cum_yards_gained_per_g_z_vs_league (REAL)\n",
      "cum_yards_allowed_per_g_rank_vs_league (REAL)\n",
      "cum_yards_allowed_per_g_z_vs_league (REAL)\n",
      "rush_yards (REAL)\n",
      "rush_yards_allowed (REAL)\n",
      "cum_rush_yards_sum (REAL)\n",
      "cum_rush_yards_allowed_sum (REAL)\n",
      "cum_rush_yards_per_g (REAL)\n",
      "cum_rush_yards_allowed_per_g (REAL)\n",
      "cum_rush_yards_per_g_rank_vs_league (REAL)\n",
      "cum_rush_yards_per_g_z_vs_league (REAL)\n",
      "cum_rush_yards_allowed_per_g_rank_vs_league (REAL)\n",
      "cum_rush_yards_allowed_per_g_z_vs_league (REAL)\n",
      "pass_yards (REAL)\n",
      "pass_yards_allowed (REAL)\n",
      "cum_pass_yards_sum (REAL)\n",
      "cum_pass_yards_allowed_sum (REAL)\n",
      "cum_pass_yards_per_g (REAL)\n",
      "cum_pass_yards_allowed_per_g (REAL)\n",
      "cum_pass_yards_per_g_rank_vs_league (REAL)\n",
      "cum_pass_yards_per_g_z_vs_league (REAL)\n",
      "cum_pass_yards_allowed_per_g_rank_vs_league (REAL)\n",
      "cum_pass_yards_allowed_per_g_z_vs_league (REAL)\n",
      "total_off_epa (REAL)\n",
      "total_def_epa (REAL)\n",
      "cum_total_off_epa_sum (REAL)\n",
      "cum_total_def_epa_sum (REAL)\n",
      "cum_total_off_epa_per_g (REAL)\n",
      "cum_total_def_epa_per_g (REAL)\n",
      "cum_total_off_epa_per_g_rank_vs_league (REAL)\n",
      "cum_total_off_epa_per_g_z_vs_league (REAL)\n",
      "cum_total_def_epa_per_g_rank_vs_league (REAL)\n",
      "cum_total_def_epa_per_g_z_vs_league (REAL)\n",
      "rush_off_epa (REAL)\n",
      "rush_def_epa (REAL)\n",
      "cum_rush_off_epa_sum (REAL)\n",
      "cum_rush_def_epa_sum (REAL)\n",
      "cum_rush_off_epa_per_g (REAL)\n",
      "cum_rush_def_epa_per_g (REAL)\n",
      "cum_rush_off_epa_per_g_rank_vs_league (REAL)\n",
      "cum_rush_off_epa_per_g_z_vs_league (REAL)\n",
      "cum_rush_def_epa_per_g_rank_vs_league (REAL)\n",
      "cum_rush_def_epa_per_g_z_vs_league (REAL)\n",
      "pass_off_epa (REAL)\n",
      "pass_def_epa (REAL)\n",
      "cum_pass_off_epa_sum (REAL)\n",
      "cum_pass_def_epa_sum (REAL)\n",
      "cum_pass_off_epa_per_g (REAL)\n",
      "cum_pass_def_epa_per_g (REAL)\n",
      "cum_pass_off_epa_per_g_rank_vs_league (REAL)\n",
      "cum_pass_off_epa_per_g_z_vs_league (REAL)\n",
      "cum_pass_def_epa_per_g_rank_vs_league (REAL)\n",
      "cum_pass_def_epa_per_g_z_vs_league (REAL)\n",
      "rz_drives (INTEGER)\n",
      "rz_td_drives (INTEGER)\n",
      "rz_td_pct (REAL)\n",
      "cum_rz_off_td_drives (INTEGER)\n",
      "cum_rz_off_drives (INTEGER)\n",
      "cum_rz_off_td_pct (REAL)\n",
      "cum_rz_off_td_pct_rank_vs_league (REAL)\n",
      "cum_rz_off_td_pct_z_vs_league (REAL)\n",
      "rz_drives_allowed (INTEGER)\n",
      "rz_td_drives_allowed (INTEGER)\n",
      "rz_td_pct_allowed (REAL)\n",
      "cum_rz_def_td_drives (INTEGER)\n",
      "cum_rz_def_drives (INTEGER)\n",
      "cum_rz_def_td_pct_allowed (REAL)\n",
      "cum_rz_def_td_pct_allowed_rank_vs_league (REAL)\n",
      "cum_rz_def_td_pct_allowed_z_vs_league (REAL)\n",
      "sacks_allowed (INTEGER)\n",
      "qb_hits_allowed (INTEGER)\n",
      "pressures_allowed (INTEGER)\n",
      "cum_sacks_allowed_sum (INTEGER)\n",
      "cum_qb_hits_allowed_sum (INTEGER)\n",
      "cum_pressures_allowed_sum (INTEGER)\n",
      "cum_sacks_allowed_per_g (REAL)\n",
      "cum_qb_hits_allowed_per_g (REAL)\n",
      "cum_pressures_allowed_per_g (REAL)\n",
      "cum_sacks_allowed_per_g_rank_vs_league (REAL)\n",
      "cum_sacks_allowed_per_g_z_vs_league (REAL)\n",
      "cum_qb_hits_allowed_per_g_rank_vs_league (REAL)\n",
      "cum_qb_hits_allowed_per_g_z_vs_league (REAL)\n",
      "cum_pressures_allowed_per_g_rank_vs_league (REAL)\n",
      "cum_pressures_allowed_per_g_z_vs_league (REAL)\n",
      "sacks_caused (INTEGER)\n",
      "qb_hits_caused (INTEGER)\n",
      "pressures_caused (INTEGER)\n",
      "cum_sacks_caused_sum (INTEGER)\n",
      "cum_qb_hits_caused_sum (INTEGER)\n",
      "cum_pressures_caused_sum (INTEGER)\n",
      "cum_sacks_caused_per_g (REAL)\n",
      "cum_qb_hits_caused_per_g (REAL)\n",
      "cum_pressures_caused_per_g (REAL)\n",
      "cum_sacks_caused_per_g_rank_vs_league (REAL)\n",
      "cum_sacks_caused_per_g_z_vs_league (REAL)\n",
      "cum_qb_hits_caused_per_g_rank_vs_league (REAL)\n",
      "cum_qb_hits_caused_per_g_z_vs_league (REAL)\n",
      "cum_pressures_caused_per_g_rank_vs_league (REAL)\n",
      "cum_pressures_caused_per_g_z_vs_league (REAL)\n",
      "rush_attempts (INTEGER)\n",
      "pass_attempts (INTEGER)\n",
      "total_tds (REAL)\n",
      "phi_srs_week (REAL)\n",
      "opp_srs_week (REAL)\n",
      "expected_mov_srs (REAL)\n",
      "quality_of_win_srs (REAL)\n",
      "home_team (TEXT)\n",
      "away_team (TEXT)\n",
      "home_score (INTEGER)\n",
      "away_score (INTEGER)\n",
      "loss (INTEGER)\n",
      "cumulative_losses (INTEGER)\n",
      "cumulative_turnover_differential (INTEGER)\n",
      "rush_tds (REAL)\n",
      "pass_tds (REAL)\n",
      "cum_win_pts (REAL)\n",
      "\n",
      "\n",
      "EXTRACTED ENTITIES (use ONLY these values):\n",
      "- season: None\n",
      "- week: None\n",
      "- player: None\n",
      "- opponent: None\n",
      "\n",
      "\n",
      "Rules:\n",
      "- Use ONLY the extracted entities above when building the WHERE clause.\n",
      "- NEVER pull team names or player names from the natural language question.\n",
      "- opponent_team MUST use the abbreviation exactly as provided (e.g., 'DAL'), not full team name.\n",
      "- Use player_display_name for player filters.\n",
      "- Do NOT filter by team since all teams are PHI\n",
      "- If the user asks for total 'yards' for a player, include both `passing_yards` and `rushing_yards` if available.\n",
      "- If the user asks about a change over be sure to include relevant time fields like year or week\n",
      "- If including filters for position, only use standard abbreviations (e.g., 'QB', 'WR', 'RB').\n",
      "- Do NOT include any field in the WHERE clause that is not listed in the table schema.\n",
      " Only extract opponents that are in this list: ARI, ATL, BAL, BUF, CAR, CHI, CIN, CLE, DAL, DEN, DET, GB, HOU, IND, JAX, KC, LV, LAC, LAR, MIA, MIN, NE, NO, NYG, NYJ, PHI, PIT, SEA, SF, TB, TEN, WAS\n",
      "\n",
      "- Return ONLY the SQL query with no commentary.\n",
      "\n",
      "User question:\n",
      "in which game did the eagles take the most sacks?\n",
      "\n",
      "üü® USER QUESTION: in which game did the eagles take the most sacks?\n",
      "üß† Intent: team_game\n",
      "üß© Entities: {'season': None, 'week': None, 'player': None, 'opponent': None}\n",
      "üìÑ Table: games\n",
      "üü¶ Original SQL:\n",
      " SELECT game_id, season, week, sacks_allowed \n",
      "FROM games \n",
      "WHERE home_team = 'PHI' OR away_team = 'PHI' \n",
      "ORDER BY sacks_allowed DESC \n",
      "LIMIT 1;\n",
      "üß† Reflection:\n",
      " 1. **Did the SQL query match the user‚Äôs intent?**\n",
      "   - Yes, the SQL query matches the user's intent to find the game in which the Eagles took the most sacks.\n",
      "\n",
      "2. **Were the correct filters, fields, and aggregations used?**\n",
      "   - The query correctly selects the `game_id`, `season`, `week`, and `sacks_allowed` fields. However, filtering for `home_team = 'PHI' OR away_team = 'PHI'` is unnecessary since all data pertains to the Eagles.\n",
      "\n",
      "3. **Were all given rules followed?**\n",
      "   - The rule regarding filtering for the team is not followed, as it is not needed.\n",
      "\n",
      "4. **Do the results look reasonable?**\n",
      "   - The results appear reasonable, showing that in the game against Washington in 2020, the Eagles allowed 8 sacks, which is a plausible number.\n",
      "\n",
      "**Conclusion:**\n",
      "The SQL query is mostly correct in terms of intent and results, but it includes an unnecessary filter for the team. The correct answer is that the Eagles took the most sacks in the game against Washington in 2020, allowing 8 sacks.\n",
      "üîÅ Regenerated SQL:\n",
      " None\n",
      "üìä Result:\n",
      "            game_id  season  week  sacks_allowed\n",
      "0  2020_01_PHI_WAS    2020     1              8\n"
     ]
    }
   ],
   "source": [
    " #Test Questions\n",
    "#question = \"How many wins did the Eagles have against Dallas in 2020?\" #agentic needs to assess that teh win coulm is TRUE FALSE text\n",
    "#question = \"How many passing yards did Jalen Hurts have in 2024 against Dallas?\"\n",
    "#question = \"How many touchdowns  did the eagles have in 2023 against Dallas?\" # pulls 2 rows, good case for agentic refl\n",
    "#question = \"How many yards Jalen Hurts have in 2024 against Dallas?\" #pulled only passing, fixed with rule\n",
    "#question = \"What were A.J. Brown's total receiving yards in 2023?\"\n",
    "#question = \"How many rushing yards did Miles Sanders have in his career for the eagles\"\n",
    "#question = \"Who had the most sacks for the Eagles in 2021?\"#agentic refl picked up that the SQL added !=PHI incorrectly, fixed with adjusted rule\n",
    "#question = \"how many wins did the Eagles have over the Cowboys in 2020-2022?\"#big fail. Picked season and wins column which doesn't exist\n",
    "#question = \"who was best rusher for the Eagles in 2024 ?\"\n",
    "#question = \"What tight end had the most receiving yards for the Eagles in 2023?\"# need to map TE to tight_end\n",
    "#question = \"How many receiving yards did Goedert have in 2023?\"\n",
    "#question = \"in which game did the eagles take the most sacks?\"# big fail and agentic refl caught it. picked wrong turnovers_committed column which doesn't exist and addeed \"none\" as opponent\n",
    "#question = \"What was eagles red zone touchdown performance in 2023?\"\n",
    "#question = \"How many rushing yards per game did the eagles have in 2024?\"\n",
    "#question = \"in what game did the eagles have the most rushing yards?\"#added opponent None\n",
    "#question = \"What Qb was the most accurate for the eagles in 2023?\"#Great for agent refl. returned Braden Mann which is correct because his 1 pass was complete. Think about this one. needed to filter to QB\n",
    "#question = \"what was the eagles turnover margin in 2022?\"\n",
    "#question = \"how has jalen hurts interception rate improved?\"\n",
    "#question = \"how has jalen hurts accuracy improved?\"\n",
    "#question = \"how has AJ Brown's yards after catch changed?\"#reflection caught that SQL should have included year, fixed with rule\n",
    "#question = \"how did the eagles defense improve in 2024\"#tricky one, should have pulled some element of time but pulled the season line\n",
    "\n",
    "\n",
    "\n",
    "question= \"in which game did the eagles take the most sacks?\" #good for agentic refl\n",
    "\n",
    "\n",
    "output = run_query_pipeline(question)\n",
    "\n",
    "print(\"üü® USER QUESTION:\", output[\"question\"])\n",
    "print(\"üß† Intent:\", output[\"intent\"])\n",
    "print(\"üß© Entities:\", output[\"entities\"])\n",
    "print(\"üìÑ Table:\", output[\"table\"])\n",
    "print(\"üü¶ Original SQL:\\n\", output[\"original_sql\"])\n",
    "print(\"üß† Reflection:\\n\", output[\"reflection\"])\n",
    "print(\"üîÅ Regenerated SQL:\\n\", output[\"regenerated_sql\"])\n",
    "print(\"üìä Result:\\n\", output[\"result\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
